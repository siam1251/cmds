[basics](https://www.analyticsvidhya.com/blog/2020/04/comprehensive-popular-deep-learning-interview-questions-answers/)   
[pdf](https://github.com/siam1251/cmds/blob/master/ML%20Interview%20Cheat%20sheet.pdf)     
[different activation functions](https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6)
another link [activation functions](https://towardsdatascience.com/activation-functions-in-deep-neural-networks-aae2a598f211)       
[avoid overfitting (variance)](https://machinelearningmastery.com/introduction-to-regularization-to-reduce-overfitting-and-improve-generalization-error/)  
[Different loss function](https://medium.com/@zeeshanmulla/cost-activation-loss-function-neural-network-deep-learning-what-are-these-91167825a4de)      


L1 vs L2 Regularization ?

### Regression Loss vs Classification loss

Regression Loss Functions
    * Mean Squared Error Loss
    * Mean Squared Logarithmic Error Loss
    * Mean Absolute Error Loss
Binary Classification Loss Functions
    * Binary Cross-Entropy
    * Hinge Loss
    * Squared Hinge Loss
Multi-Class Classification Loss Functions
    * Multi-Class Cross-Entropy Loss
    * Sparse Multiclass Cross-Entropy Loss
    * Kullback Leibler Divergence Loss
